{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-03T11:50:37.825775Z","iopub.execute_input":"2023-10-03T11:50:37.828292Z","iopub.status.idle":"2023-10-03T11:50:38.473760Z","shell.execute_reply.started":"2023-10-03T11:50:37.828255Z","shell.execute_reply":"2023-10-03T11:50:38.472812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np \nimport PIL \nimport tensorflow as tf\nfrom tensorflow import keras \nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom pathlib import Path","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:38.479419Z","iopub.execute_input":"2023-10-03T11:50:38.480165Z","iopub.status.idle":"2023-10-03T11:50:42.229514Z","shell.execute_reply.started":"2023-10-03T11:50:38.480129Z","shell.execute_reply":"2023-10-03T11:50:42.227997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Download the dataset","metadata":{}},{"cell_type":"code","source":"# Classes we have in our data set.\ntotal_classes = os.listdir(\"/kaggle/input/brain-mri-scans-for-brain-tumor-classification/data\")\ntotal_classes","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:42.230948Z","iopub.execute_input":"2023-10-03T11:50:42.231601Z","iopub.status.idle":"2023-10-03T11:50:42.249390Z","shell.execute_reply.started":"2023-10-03T11:50:42.231567Z","shell.execute_reply":"2023-10-03T11:50:42.248243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total number of images per class.\nimages_path = Path(\"/kaggle/input/brain-mri-scans-for-brain-tumor-classification/data\")\n\nfor c in total_classes:\n  print(f'* {c}', '=',len(os.listdir(os.path.join(images_path, c))), 'images')","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:42.255977Z","iopub.execute_input":"2023-10-03T11:50:42.256901Z","iopub.status.idle":"2023-10-03T11:50:42.268190Z","shell.execute_reply.started":"2023-10-03T11:50:42.256850Z","shell.execute_reply":"2023-10-03T11:50:42.267114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# random\nimport random\nimport cv2\n\n# Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:42.269519Z","iopub.execute_input":"2023-10-03T11:50:42.270445Z","iopub.status.idle":"2023-10-03T11:50:42.305547Z","shell.execute_reply.started":"2023-10-03T11:50:42.270414Z","shell.execute_reply":"2023-10-03T11:50:42.304670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's display 1 image per class.\n\nfig,ax = plt.subplots(1,4,figsize=(10,4))\nax = ax.flat\nfor i,c in enumerate(total_classes):\n  img_total_class = list(Path(os.path.join(images_path, c)).glob(\"*.jpg\"))\n  img_selected = random.choice(img_total_class)\n  img_BGR = cv2.imread(str(img_selected))\n  img_RGB = cv2.cvtColor(img_BGR, cv2.COLOR_BGR2RGB)\n  height,width,channel = img_RGB.shape\n  ax[i].imshow(img_RGB)\n  ax[i].set_title(f\"{img_selected.parent.stem}\\nheight:{height}\\nwidth:{width}\")\n  ax[i].axis(\"off\")\n\nfig.tight_layout()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:42.306747Z","iopub.execute_input":"2023-10-03T11:50:42.307105Z","iopub.status.idle":"2023-10-03T11:50:42.958207Z","shell.execute_reply.started":"2023-10-03T11:50:42.307064Z","shell.execute_reply":"2023-10-03T11:50:42.957250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nimg_height = 180\nimg_width = 180","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:42.959711Z","iopub.execute_input":"2023-10-03T11:50:42.960424Z","iopub.status.idle":"2023-10-03T11:50:42.965716Z","shell.execute_reply.started":"2023-10-03T11:50:42.960338Z","shell.execute_reply":"2023-10-03T11:50:42.964646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = tf.keras.utils.image_dataset_from_directory(\n    images_path,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=123,\n    image_size = (img_height, img_width),\n    batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:42.967376Z","iopub.execute_input":"2023-10-03T11:50:42.968128Z","iopub.status.idle":"2023-10-03T11:50:46.867935Z","shell.execute_reply.started":"2023-10-03T11:50:42.968096Z","shell.execute_reply":"2023-10-03T11:50:46.866931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_ds = tf.keras.utils.image_dataset_from_directory(\n    images_path,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:46.869115Z","iopub.execute_input":"2023-10-03T11:50:46.869455Z","iopub.status.idle":"2023-10-03T11:50:46.955158Z","shell.execute_reply.started":"2023-10-03T11:50:46.869425Z","shell.execute_reply":"2023-10-03T11:50:46.954084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:46.956434Z","iopub.execute_input":"2023-10-03T11:50:46.957454Z","iopub.status.idle":"2023-10-03T11:50:46.962786Z","shell.execute_reply.started":"2023-10-03T11:50:46.957408Z","shell.execute_reply":"2023-10-03T11:50:46.961820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize the data","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt \n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i+1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:46.964790Z","iopub.execute_input":"2023-10-03T11:50:46.965561Z","iopub.status.idle":"2023-10-03T11:50:48.356576Z","shell.execute_reply.started":"2023-10-03T11:50:46.965529Z","shell.execute_reply":"2023-10-03T11:50:48.355770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image_batch, labels_batch in train_ds:\n    print(image_batch.shape)\n    print(labels_batch.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:48.357977Z","iopub.execute_input":"2023-10-03T11:50:48.358517Z","iopub.status.idle":"2023-10-03T11:50:48.855379Z","shell.execute_reply.started":"2023-10-03T11:50:48.358485Z","shell.execute_reply":"2023-10-03T11:50:48.854345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Configure the dataset for performance","metadata":{}},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:48.859822Z","iopub.execute_input":"2023-10-03T11:50:48.860384Z","iopub.status.idle":"2023-10-03T11:50:48.874624Z","shell.execute_reply.started":"2023-10-03T11:50:48.860357Z","shell.execute_reply":"2023-10-03T11:50:48.873519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Standardize the data","metadata":{}},{"cell_type":"code","source":"normalization_layer = layers.Rescaling(1./255)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:48.876144Z","iopub.execute_input":"2023-10-03T11:50:48.876478Z","iopub.status.idle":"2023-10-03T11:50:48.889031Z","shell.execute_reply.started":"2023-10-03T11:50:48.876447Z","shell.execute_reply":"2023-10-03T11:50:48.887913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nimage_batch, labels_batch = next(iter(normalized_ds))\nfirst_image = image_batch[0]\n\n# Notice the pixel values are now in '[0,1]'\n\nprint(np.min(first_image), np.max(first_image))","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:48.890142Z","iopub.execute_input":"2023-10-03T11:50:48.891307Z","iopub.status.idle":"2023-10-03T11:50:50.708706Z","shell.execute_reply.started":"2023-10-03T11:50:48.891270Z","shell.execute_reply":"2023-10-03T11:50:50.707509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create the Model","metadata":{}},{"cell_type":"code","source":"num_classes = len(class_names)\n\nmodel = Sequential([\n    layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n    layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n    layers.MaxPooling2D(),\n    layers.Flatten(),\n    layers.Dense(128, activation=\"relu\"),\n    layers.Dense(num_classes)\n])","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:50.710362Z","iopub.execute_input":"2023-10-03T11:50:50.710736Z","iopub.status.idle":"2023-10-03T11:50:50.990575Z","shell.execute_reply.started":"2023-10-03T11:50:50.710700Z","shell.execute_reply":"2023-10-03T11:50:50.989645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compile the Model","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer=\"adam\",\n             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n             metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:50.992079Z","iopub.execute_input":"2023-10-03T11:50:50.992615Z","iopub.status.idle":"2023-10-03T11:50:51.012101Z","shell.execute_reply.started":"2023-10-03T11:50:50.992583Z","shell.execute_reply":"2023-10-03T11:50:51.011134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:51.013557Z","iopub.execute_input":"2023-10-03T11:50:51.014136Z","iopub.status.idle":"2023-10-03T11:50:51.043753Z","shell.execute_reply.started":"2023-10-03T11:50:51.014103Z","shell.execute_reply":"2023-10-03T11:50:51.042934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train the Model","metadata":{}},{"cell_type":"code","source":"epochs = 10 \n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=epochs)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:50:51.044750Z","iopub.execute_input":"2023-10-03T11:50:51.045128Z","iopub.status.idle":"2023-10-03T11:51:07.781818Z","shell.execute_reply.started":"2023-10-03T11:50:51.045093Z","shell.execute_reply":"2023-10-03T11:51:07.780740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing the results","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8,8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title(\"Training and Validation Accuracy\")\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:51:07.783478Z","iopub.execute_input":"2023-10-03T11:51:07.785263Z","iopub.status.idle":"2023-10-03T11:51:08.217167Z","shell.execute_reply.started":"2023-10-03T11:51:07.785209Z","shell.execute_reply":"2023-10-03T11:51:08.216267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Augmentation","metadata":{}},{"cell_type":"code","source":"data_augmentation = keras.Sequential(\n[\n    layers.RandomFlip(\"horizontal\",\n                     input_shape=(img_height,\n                                 img_width,\n                                  3)),\n    \n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1)\n])","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:51:08.218602Z","iopub.execute_input":"2023-10-03T11:51:08.219221Z","iopub.status.idle":"2023-10-03T11:51:08.375056Z","shell.execute_reply.started":"2023-10-03T11:51:08.219186Z","shell.execute_reply":"2023-10-03T11:51:08.374071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i+1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:51:08.376664Z","iopub.execute_input":"2023-10-03T11:51:08.377365Z","iopub.status.idle":"2023-10-03T11:51:09.179274Z","shell.execute_reply.started":"2023-10-03T11:51:08.377331Z","shell.execute_reply":"2023-10-03T11:51:09.178376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adding Dropout layer","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    data_augmentation,\n    layers.Rescaling(1./255),\n    layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.2),\n    layers.Flatten(),\n    layers.Dense(128, activation=\"relu\"),\n    layers.Dense(num_classes, name=\"outputs\")\n])","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:51:09.180666Z","iopub.execute_input":"2023-10-03T11:51:09.181705Z","iopub.status.idle":"2023-10-03T11:51:09.388911Z","shell.execute_reply.started":"2023-10-03T11:51:09.181665Z","shell.execute_reply":"2023-10-03T11:51:09.387796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=\"adam\",\n                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:51:09.390655Z","iopub.execute_input":"2023-10-03T11:51:09.391361Z","iopub.status.idle":"2023-10-03T11:51:09.402456Z","shell.execute_reply.started":"2023-10-03T11:51:09.391325Z","shell.execute_reply":"2023-10-03T11:51:09.401541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:51:09.404020Z","iopub.execute_input":"2023-10-03T11:51:09.405114Z","iopub.status.idle":"2023-10-03T11:51:09.438181Z","shell.execute_reply.started":"2023-10-03T11:51:09.405079Z","shell.execute_reply":"2023-10-03T11:51:09.437110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 100\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=epochs)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:51:09.439410Z","iopub.execute_input":"2023-10-03T11:51:09.439836Z","iopub.status.idle":"2023-10-03T11:52:52.808715Z","shell.execute_reply.started":"2023-10-03T11:51:09.439794Z","shell.execute_reply":"2023-10-03T11:52:52.807674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8,8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title(\"Training and Validation Accuracy\")\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T11:52:52.810480Z","iopub.execute_input":"2023-10-03T11:52:52.810873Z","iopub.status.idle":"2023-10-03T11:52:53.280283Z","shell.execute_reply.started":"2023-10-03T11:52:52.810826Z","shell.execute_reply":"2023-10-03T11:52:53.279306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict on new data","metadata":{}},{"cell_type":"code","source":"giloma_path = \"/kaggle/input/brain-mri-scans-for-brain-tumor-classification/data/meningioma/Te-me_0015.jpg\"\n\n\nimg = tf.keras.utils.load_img(\n    giloma_path, target_size=(img_height, img_width)\n)\nimg_array = tf.keras.utils.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0) # Create a batch\n\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(class_names[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T12:04:55.158430Z","iopub.execute_input":"2023-10-03T12:04:55.158776Z","iopub.status.idle":"2023-10-03T12:04:55.225052Z","shell.execute_reply.started":"2023-10-03T12:04:55.158749Z","shell.execute_reply":"2023-10-03T12:04:55.224107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Convert the model to TfLite\n\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\n## Save the model\nwith open('brain_model.tflite', 'wb') as f:\n    f.write(tflite_model)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T12:10:02.688848Z","iopub.execute_input":"2023-10-03T12:10:02.689299Z","iopub.status.idle":"2023-10-03T12:10:06.552935Z","shell.execute_reply.started":"2023-10-03T12:10:02.689262Z","shell.execute_reply":"2023-10-03T12:10:06.551924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the Keras model as an HDF5 file\nmodel.save(\"brain_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-10-03T12:11:40.970361Z","iopub.execute_input":"2023-10-03T12:11:40.970966Z","iopub.status.idle":"2023-10-03T12:11:41.123225Z","shell.execute_reply.started":"2023-10-03T12:11:40.970926Z","shell.execute_reply":"2023-10-03T12:11:41.122156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}